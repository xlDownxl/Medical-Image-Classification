{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2               \n",
    "import numpy as np         \n",
    "import os                \n",
    "from random import shuffle \n",
    "from tqdm import tqdm     \n",
    "import tensorflow as tf\n",
    "import time\n",
    "import keras\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from keras import losses\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.engine import Layer\n",
    "from keras.models import *\n",
    "import keras.backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.utils import *\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Windows\n",
    "IMG_DIR = '/Users/Niclas/Dropbox/BA/x'\n",
    "LABEL_DIR = '/Users/Niclas/Dropbox/BA/y'\n",
    "\n",
    "AUG_IMG_DIR = '/Users/Niclas/Dropbox/BA/AUGX'\n",
    "AUG_LABEL_DIR = '/Users/Niclas/Dropbox/BA/AUGY'\n",
    "\n",
    "seed=1\n",
    "\n",
    "#check if GPU works\n",
    "#np.set_printoptions(threshold=np.inf)\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncategorical(one_hot):      #convert one hot array to sparse\n",
    "    sparse=[]\n",
    "    for i in range(len(one_hot)):\n",
    "        if(one_hot[i,0]>one_hot[i,1]):\n",
    "            sparse.append(0)\n",
    "        else:\n",
    "            sparse.append(255)\n",
    "    sparse=np.array(sparse)\n",
    "    return sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate augmentation Basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(IMG_DIR)): #iterate through all images in the folder\n",
    "        path = os.path.join(IMG_DIR,img) \n",
    "        img_num = img.split('.')[0]\n",
    "        img = np.array(cv2.imread(path)) #read image\n",
    "            \n",
    "        path2 = os.path.join(LABEL_DIR,'polyraster-')   \n",
    "        path2 +=img_num\n",
    "        path2+= '.png'  \n",
    "        label =  cv2.imread(path2,cv2.IMREAD_GRAYSCALE)  #read label     \n",
    "\n",
    "        testing_data.append([image,label]) \n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=process_image_data()    #generate data for augmentation\n",
    "\n",
    "train_x = np.array([i[0] for i in data])    #split data into images and labels\n",
    "train_y =np.array([i[1] for i in data])\n",
    "\n",
    "train_y=train_y.reshape(-1,1704,2272,1) #add 4th dimension\n",
    "print(np.array(train_x).shape)\n",
    "print(np.array(train_y).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=1000  #amount of augmented images that will be generated\n",
    "\n",
    "data_gen_args = dict(featurewise_center=True,  #augmentation attributes\n",
    "                     featurewise_std_normalization=True,\n",
    "                     rotation_range=20.,\n",
    "                     width_shift_range=0.02,\n",
    "                     height_shift_range=0.02,\n",
    "                     zoom_range=0.01,\n",
    "                     horizontal_flip=True,\n",
    "                     fill_mode=\"constant\",\n",
    "                     cval=0,\n",
    "                     data_format=\"channels_last\"\n",
    "                    ) \n",
    "image_datagen = ImageDataGenerator(**data_gen_args) \n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "image_datagen.fit(train_x)  #fit the generator on data to use featurewise_center\n",
    "mask_datagen.fit(train_y)\n",
    "\n",
    "\n",
    "#saves the defined amount of augmented images to the specified directory\n",
    "i = 0\n",
    "for batch in image_datagen.flow(x=train_x, batch_size=1,\n",
    "                          save_to_dir=AUG_IMG_DIR, save_prefix='Image', save_format='png',seed=seed):   \n",
    "    i += 1\n",
    "    if i >= images:\n",
    "         break  \n",
    "i = 0\n",
    "for batch in mask_datagen.flow(x=train_y, batch_size=1, \n",
    "                          save_to_dir=AUG_LABEL_DIR, save_prefix='Label', save_format='png',seed=seed):\n",
    "    i += 1\n",
    "    if i >= images:\n",
    "          break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_augment_data():\n",
    "    aug_data = []\n",
    "    for img in tqdm(os.listdir(AUG_IMG_DIR)): #iterate over augmentation folder\n",
    "        img_num = img.split('_')  \n",
    "        img_num='_'+img_num[1]+'_'+img_num[2]\n",
    "               \n",
    "        path='Image'                        \n",
    "        path=path+img_num\n",
    "        path=os.path.join(AUG_IMG_DIR,path)        \n",
    "        img = cv2.imread(path)   #read in image\n",
    "        \n",
    "        image_length=img.shape[0]\n",
    "        image_width=img.shape[1]    \n",
    "        half_length=int(image_length/2)\n",
    "        half_width=int(image_width/2)\n",
    "                                   \n",
    "        path_label='Label'+img_num    \n",
    "        path_label = os.path.join(AUG_LABEL_DIR,path_label)\n",
    "        label = cv2.imread(path_label,cv2.IMREAD_GRAYSCALE) #read label\n",
    "   \n",
    "        label=label.flatten() \n",
    "      \n",
    "        label=keras.utils.to_categorical(label, 2)  #flatten the label to transform it into one hot\n",
    "        label=label.reshape(1704,2272,2)\n",
    "                \n",
    "        image1 = img[:half_length,:half_width]  # cut the images into equally sized parts to reduce memorey usage in the gpu\n",
    "        image2 = img[:half_length,half_width:]\n",
    "        image3 = img[half_length:,:half_width]       \n",
    "        image4 = img[half_length:,half_width:]\n",
    "\n",
    "        label1 = label[:half_length,:half_width]\n",
    "        label2 = label[half_length:,:half_width]\n",
    "        label3 = label[:half_length,half_width:]\n",
    "        label4 = label[half_length:,half_width:]\n",
    "        \n",
    "        aug_data.append([image1,label1]) \n",
    "        aug_data.append([image2,label2]) \n",
    "        aug_data.append([image3,label3]) \n",
    "        aug_data.append([image4,label4]) \n",
    "    shuffle(aug_data)\n",
    "    return aug_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=process_augment_data() #generate augmented data\n",
    "\n",
    "augment_x = np.array([i[0] for i in data])   #split into images and labels\n",
    "augment_y = np.array([i[1] for i in data]) \n",
    "\n",
    "print(augment_x.shape)\n",
    "print(augment_y.shape)\n",
    "\n",
    "train_test_split=2000  #validation split\n",
    "augment_x_train=augment_x[:train_test_split]\n",
    "augment_x_test=augment_x[train_test_split:]\n",
    "\n",
    "augment_y_train=augment_y[:train_test_split]\n",
    "augment_y_test=augment_y[train_test_split:]\n",
    "\n",
    "print(augment_x_train.shape)\n",
    "print(augment_y_train.shape)\n",
    "print(augment_x_test.shape)\n",
    "print(augment_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kernel = 5\n",
    "pad = 2\n",
    "pool_size = 2\n",
    "\n",
    "c=Input(shape=(852,1136,3)) \n",
    "\n",
    "a1=ZeroPadding2D(padding=(pad,pad)) (c)  \n",
    "a2=Conv2D(64, kernel, kernel, border_mode='valid',kernel_initializer=initializers.TruncatedNormal()) (a1)\n",
    "a3=BatchNormalization() (a2)\n",
    "a4=Activation('relu') (a3)\n",
    "a5=MaxPooling2D(pool_size=(pool_size, pool_size)) (a4)\n",
    "\n",
    "b1=ZeroPadding2D(padding=(pad,pad)) (a5) \n",
    "b2=Conv2D(128, kernel, kernel, border_mode='valid',kernel_initializer=initializers.TruncatedNormal()) (b1)\n",
    "b3=BatchNormalization() (b2)\n",
    "b4=Activation('relu') (b3)\n",
    "b5=MaxPooling2D(pool_size=(pool_size, pool_size)) (b4)\n",
    "\n",
    "c1=ZeroPadding2D(padding=(pad,pad)) (b5) \n",
    "c2=Conv2D(256, kernel, kernel, border_mode='valid',kernel_initializer=initializers.TruncatedNormal()) (c1)\n",
    "c3=Dropout(0.4) (c2)\n",
    "c4=BatchNormalization() (c3)\n",
    "c5=Activation('relu') (c4)\n",
    "c6=MaxPooling2D(pool_size=(pool_size, pool_size)) (c5)\n",
    "\n",
    "d1=ZeroPadding2D(padding=(pad,pad)) (c6) \n",
    "d2=Conv2D(512, kernel, kernel, border_mode='valid',kernel_initializer=initializers.TruncatedNormal()) (d1)\n",
    "d3=Dropout(0.6) (d2)\n",
    "d4=BatchNormalization() (d3)\n",
    "d5=Activation('relu') (d4)\n",
    "\n",
    "e1=ZeroPadding2D(padding=(pad,pad)) (d5) \n",
    "e2=Conv2D(512, kernel, kernel, border_mode='valid',kernel_initializer=initializers.TruncatedNormal()) (e1)\n",
    "e3=Dropout(0.6) (e2)\n",
    "e4=BatchNormalization() (e3)\n",
    "e5=Activation('relu') (e4)\n",
    "\n",
    "f1=UpSampling2D(size=(pool_size,pool_size)) (e5)\n",
    "f2=ZeroPadding2D(padding=(pad,pad)) (f1)\n",
    "f3=Conv2D(256, kernel, kernel, border_mode='valid',kernel_initializer=initializers.TruncatedNormal()) (f2)\n",
    "f4=Dropout(0.5) (f3)\n",
    "f5=BatchNormalization() (f4)\n",
    "f6=Activation('relu') (f5)\n",
    "\n",
    "merge1=Add()([c5,f6])\n",
    "\n",
    "g1=UpSampling2D(size=(pool_size,pool_size)) (merge1)\n",
    "g2=ZeroPadding2D(padding=(pad,pad)) (g1)\n",
    "g3=Conv2D(128, kernel, kernel, border_mode='valid',kernel_initializer=initializers.TruncatedNormal()) (g2)\n",
    "g4=BatchNormalization() (g3)\n",
    "g5=Activation('relu') (g4)\n",
    "\n",
    "merge2=Add()([g5,b4])\n",
    "\n",
    "h1=UpSampling2D(size=(pool_size,pool_size)) (g5)\n",
    "h2=ZeroPadding2D(padding=(pad,pad)) (h1)\n",
    "h3=Conv2D(64, kernel, kernel, border_mode='valid',kernel_initializer=initializers.TruncatedNormal()) (h2)\n",
    "h4=BatchNormalization() (h3)\n",
    "h5=Activation('relu') (h4)\n",
    "\n",
    "i1=Conv2D(2, 1, 1, border_mode='valid',kernel_initializer=initializers.TruncatedNormal()) (h5)\n",
    "i2=Activation('softmax') (i1)\n",
    "\n",
    "model = Model(inputs=c, outputs=i2)\n",
    "print(model.output_shape)\n",
    "\n",
    "plot_model(model, to_file='network.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use adam with a learning rate of 0.01 and decay of 0.001\n",
    "#use categorical crossentropy for single class classification problem\n",
    "model.compile(loss=\"categorical_crossentropy\",metrics=['accuracy'], optimizer=optimizers.adam(lr=0.01,decay=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model with a batchsize of 1 because the memory storage in the gpu is enormous\n",
    "model.fit(augment_x_train, augment_y_train, batch_size=1, epochs=40,\n",
    "                    verbose=1,validation_data=(np.array(augment_x_test),np.array(augment_y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "model.save_weights('current_model_weights')\n",
    "model.save('current_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
